{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGp0ucY8tosy",
        "outputId": "d2e47a4c-dbfb-40b2-ae39-b43d41840a0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.52.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.52.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentacion\n"
      ],
      "metadata": {
        "id": "faWr8XVVtz39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## # Proyecto de Inteligencia de Enjambre - VRP con ACO\n",
        "\n",
        "Este proyecto implementa un algoritmo basado en colonias de hormigas para resolver problemas de ruteo de vehículos con capacidad limitada y demandas de clientes. La idea es generar rutas eficientes minimizando la distancia total y respetando las restricciones de capacidad.\n",
        "\n",
        "## Documentación de las fuentes\n",
        "\n",
        "La parte central del código está en la clase `ACOSolver`. Esta clase recibe parámetros como `alpha` y `beta` que controlan cuánto peso tienen las feromonas y la heurística en la selección de nodos, `rho` que es la tasa de evaporación, el número de iteraciones que se harán y cuántas hormigas participan en la construcción de soluciones. La función principal es `solve`, que recibe los nodos, la matriz de distancias y la capacidad del vehículo, y devuelve las rutas optimizadas. Dentro de `solve`, primero se preparan los datos, luego se ejecuta el ACO y finalmente se hace una optimización local 2-opt para mejorar cada ruta.\n",
        "\n",
        "Hay funciones auxiliares que ayudan en el preprocesamiento y construcción de soluciones. Por ejemplo, `greedy_cluster_mejorado` agrupa los clientes en clusters respetando la capacidad del vehículo y priorizando clientes de mayor demanda y cercanía, mientras que `aplicar_aco_solver_clusters` aplica el solver a cada cluster y calcula la distancia total de todas las rutas. La clase `Graph` simplemente facilita la carga de datos desde archivos parquet, entregando tanto los nodos como la matriz de distancias de forma práctica.\n",
        "\n",
        "El proyecto también incluye una función `evaluar_algoritmo_aco`, que recorre un conjunto de problemas, genera clusters, aplica el solver y compara los resultados con un benchmark, calculando errores, tiempo de ejecución y memoria utilizada.\n",
        "\n",
        "En cuanto a los parámetros, las entradas principales de la función `solve` son los nodos (con coordenadas y demandas), la matriz de distancias y la capacidad. Los hiperparámetros son `alpha`, `beta`, `rho`, número de iteraciones y número de hormigas. La salida son las rutas encontradas y la distancia total, que se puede obtener con `solution_length`.\n",
        "\n",
        "## Análisis comparativo de estadísticas\n",
        "\n",
        "Para evaluar cómo funciona nuestro ACO frente al benchmark, se calculan varios errores y métricas:\n",
        "\n",
        "- Error absoluto: diferencia entre la distancia calculada por ACO y la distancia del benchmark.\n",
        "- Error relativo: relación entre el error absoluto y la distancia del benchmark.\n",
        "- Error promedio (MAE) y error cuadrático promedio (MSE) a lo largo de todos los problemas.\n",
        "- Además se mide el tiempo de ejecución y la memoria utilizada.\n",
        "\n",
        "Estas métricas permiten ver si el algoritmo se acerca a la solución óptima y cómo se comporta en términos de eficiencia y uso de recursos. También se pueden generar gráficos de comparación entre ACO y benchmark para visualizar tendencias y ver cuáles problemas presentan mayores diferencias.\n",
        "\n",
        "## Diagrama de flujo de datos\n",
        "\n",
        "El flujo de datos en el proyecto es sencillo: primero se cargan los nodos y la matriz de distancias, se obtiene la información de coordenadas y demandas y se define la capacidad de los vehículos. Luego se realiza el clustering greedy para agrupar clientes por vehículo. Cada cluster pasa al ACO, que construye rutas y las optimiza localmente. Finalmente, se calculan las distancias, se comparan con el benchmark, se calculan los errores y se exportan los resultados.\n",
        "\n",
        "```text\n",
        "Archivos Benchmark / parquet\n",
        "        │\n",
        "        ▼\n",
        "Cargar nodos y matriz de distancias\n",
        "        │\n",
        "        ▼\n",
        "Preprocesamiento (coords, demandas, capacidad)\n",
        "        │\n",
        "        ▼\n",
        "Clustering greedy por capacidad\n",
        "        │\n",
        "        ▼\n",
        "Aplicar ACO a cada cluster\n",
        "        │\n",
        "        ▼\n",
        "Optimización local 2-opt\n",
        "        │\n",
        "        ▼\n",
        "Rutas finales y distancia total\n",
        "        │\n",
        "        ▼\n",
        "Comparación con benchmark y cálculo de errores\n",
        "        │\n",
        "        ▼\n",
        "Exportación de resultados a Excel\n"
      ],
      "metadata": {
        "id": "TdhpivdBtU7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k33Fmpog8L3",
        "outputId": "e171626c-ba88-4933-b70e-7a2459335285"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G-cIx4rzo7m8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import multiprocessing as mp\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "import altair as alt"
      ],
      "metadata": {
        "id": "s5hVmcyVtdgW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clases"
      ],
      "metadata": {
        "id": "b7KXv5VcpPub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ACO"
      ],
      "metadata": {
        "id": "u60evyI07rQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class ACOSolver:\n",
        "    def __init__(self, alpha=1.0, beta=2.0, rho=0.1, max_iters=50, ants=20, distance_matrix=None, demands=None, depot_distances=None):\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.rho = rho\n",
        "        self.max_iters = max_iters\n",
        "        self.ants = ants\n",
        "        self.distance_matrix = distance_matrix\n",
        "        self.demands = demands\n",
        "        self.depot_distances = depot_distances\n",
        "        self.n_nodes = len(demands) if demands is not None else 0\n",
        "\n",
        "    def sum_length(self, route):\n",
        "        if not route: return 0\n",
        "        dist = self.depot_distances[route[0]]\n",
        "        for i in range(len(route)-1):\n",
        "            dist += self.distance_matrix[route[i]][route[i+1]]\n",
        "        dist += self.depot_distances[route[-1]]\n",
        "        return dist\n",
        "        total_distance = 0\n",
        "        # Depot -> primer nodo\n",
        "        total_distance += self.depot_distances[route[0]]\n",
        "\n",
        "        # Distancias entre nodos de la ruta\n",
        "        for i in range(len(route) - 1):\n",
        "            total_distance += self.distance_matrix[route[i]][route[i + 1]]\n",
        "\n",
        "        # Último nodo -> depot\n",
        "        total_distance += self.depot_distances[route[-1]]\n",
        "\n",
        "        return total_distance\n",
        "\n",
        "    def solution_length(self, routes):\n",
        "        return sum(self.sum_length(r) for r in routes)\n",
        "\n",
        "    def solve(self, nodes, distance_matrix, cap):\n",
        "        \"\"\"Método principal de resolución\"\"\"\n",
        "        try:\n",
        "            # Preparar datos\n",
        "            self._prepare_data(nodes, distance_matrix)\n",
        "\n",
        "            # Debug: verificar datos\n",
        "            print(f\"Debug: n_nodes={self.n_nodes}, capacity={cap}\")\n",
        "            print(f\"Debug: demands shape={len(self.demands)}, depot_distances shape={len(self.depot_distances)}\")\n",
        "\n",
        "            # Resolver con ACO capacitado\n",
        "            raw_paths = self._capacitated_aco(cap)\n",
        "            print(f\"Debug: raw_paths encontrados: {len(raw_paths) if raw_paths else 0}\")\n",
        "\n",
        "            if not raw_paths:\n",
        "                print(\"Warning: No se encontraron rutas en ACO capacitado\")\n",
        "                return []\n",
        "\n",
        "            # Optimizar cada ruta localmente\n",
        "            optimized_paths = []\n",
        "            for i, path in enumerate(raw_paths):\n",
        "                if path and len(path) > 0:\n",
        "                    optimized_path = self._local_search_2opt(path)\n",
        "                    if optimized_path and len(optimized_path) > 0:\n",
        "                        optimized_paths.append(optimized_path)\n",
        "                        print(f\"Debug: ruta {i} optimizada: {optimized_path}\")\n",
        "\n",
        "            print(f\"Debug: {len(optimized_paths)} rutas finales\")\n",
        "            return optimized_paths\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error en solve: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return []\n",
        "\n",
        "    def _prepare_data(self, nodes, distance_matrix):\n",
        "        \"\"\"Prepara los datos para el algoritmo\"\"\"\n",
        "        # Agregar distancias al depot\n",
        "        nodes = nodes.copy()\n",
        "        nodes[\"d0\"] = distance_matrix.iloc[0]\n",
        "\n",
        "        # Extraer datos necesarios\n",
        "        self.depot_distances = nodes[\"d0\"].values\n",
        "        self.demands = nodes[\"demand\"].values\n",
        "        self.distance_matrix = distance_matrix.values\n",
        "        self.n_nodes = len(nodes)\n",
        "\n",
        "        print(f\"Debug: Datos preparados - nodos: {self.n_nodes}\")\n",
        "\n",
        "    def _capacitated_aco(self, capacity):\n",
        "        \"\"\"ACO principal con restricciones de capacidad\"\"\"\n",
        "        try:\n",
        "            # Preparar matrices\n",
        "            d = self.distance_matrix.copy()\n",
        "            np.fill_diagonal(d, np.inf)\n",
        "\n",
        "            tau = np.ones_like(d) * 0.1  # Feromonas iniciales pequeñas\n",
        "            eta = np.divide(1.0, d, out=np.zeros_like(d), where=d>0)\n",
        "            eta[eta == np.inf] = 0\n",
        "\n",
        "            best_routes = []\n",
        "            best_distance = float('inf')\n",
        "\n",
        "            for iteration in range(self.max_iters):\n",
        "                iteration_routes = []\n",
        "\n",
        "                for ant in range(self.ants):\n",
        "                    routes = self._construct_solution(tau, eta, capacity)\n",
        "                    if routes:\n",
        "                        iteration_routes.extend(routes)\n",
        "                        total_distance = self.solution_length(routes)\n",
        "\n",
        "                        if total_distance < best_distance:\n",
        "                            best_distance = total_distance\n",
        "                            best_routes = [route.copy() for route in routes]\n",
        "\n",
        "                # Actualizar feromonas\n",
        "                if iteration_routes:\n",
        "                    self._update_pheromones(tau, iteration_routes)\n",
        "\n",
        "                if iteration % 10 == 0:\n",
        "                    print(f\"Debug: Iteración {iteration}, mejor distancia: {best_distance:.2f}\")\n",
        "\n",
        "            print(f\"Debug: ACO terminado, {len(best_routes)} rutas encontradas\")\n",
        "            return best_routes\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error en _capacitated_aco: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _construct_solution(self, tau, eta, capacity):\n",
        "        \"\"\"Construye una solución completa respetando capacidades\"\"\"\n",
        "        try:\n",
        "            unvisited = set(range(1, self.n_nodes))  # Excluir depot (nodo 0)\n",
        "            routes = []\n",
        "\n",
        "            while unvisited:\n",
        "                route = self._construct_single_route(tau, eta, capacity, unvisited)\n",
        "                if route:\n",
        "                    routes.append(route)\n",
        "                    # Remover nodos visitados\n",
        "                    for node in route:\n",
        "                        unvisited.discard(node)\n",
        "                else:\n",
        "                    # Si no se puede construir más rutas, forzar asignación de nodos restantes\n",
        "                    if unvisited:\n",
        "                        remaining = list(unvisited)\n",
        "                        # Crear rutas individuales para nodos que no caben\n",
        "                        for node in remaining:\n",
        "                            if self.demands[node] <= capacity:\n",
        "                                routes.append([node])\n",
        "                                unvisited.remove(node)\n",
        "                    break\n",
        "\n",
        "            return routes\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error en _construct_solution: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _construct_single_route(self, tau, eta, capacity, available_nodes):\n",
        "        \"\"\"Construye una sola ruta respetando capacidad\"\"\"\n",
        "        try:\n",
        "            route = []\n",
        "            current_capacity = capacity\n",
        "            remaining_nodes = available_nodes.copy()\n",
        "            current_node = 0  # Empezar desde depot\n",
        "\n",
        "            while remaining_nodes:\n",
        "                # Filtrar nodos que caben en la capacidad restante\n",
        "                feasible_nodes = [node for node in remaining_nodes\n",
        "                                if self.demands[node] <= current_capacity]\n",
        "\n",
        "                if not feasible_nodes:\n",
        "                    break\n",
        "\n",
        "                # Calcular probabilidades de selección\n",
        "                probabilities = []\n",
        "                total_weight = 0\n",
        "\n",
        "                for node in feasible_nodes:\n",
        "                    pheromone = tau[current_node, node] if current_node < len(tau) else 0.1\n",
        "                    heuristic = eta[current_node, node] if current_node < len(eta) else 1.0\n",
        "                    weight = (pheromone ** self.alpha) * (heuristic ** self.beta)\n",
        "                    probabilities.append(weight)\n",
        "                    total_weight += weight\n",
        "\n",
        "                if total_weight == 0:\n",
        "                    # Selección aleatoria si no hay información\n",
        "                    next_node = np.random.choice(feasible_nodes)\n",
        "                else:\n",
        "                    # Selección probabilística\n",
        "                    probabilities = [p / total_weight for p in probabilities]\n",
        "                    next_node = np.random.choice(feasible_nodes, p=probabilities)\n",
        "\n",
        "                # Agregar nodo a la ruta\n",
        "                route.append(next_node)\n",
        "                remaining_nodes.remove(next_node)\n",
        "                current_capacity -= self.demands[next_node]\n",
        "                current_node = next_node\n",
        "\n",
        "            return route if route else []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error en _construct_single_route: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _update_pheromones(self, tau, routes):\n",
        "        \"\"\"Actualiza feromonas\"\"\"\n",
        "        try:\n",
        "            # Evaporación\n",
        "            tau *= (1 - self.rho)\n",
        "\n",
        "            # Depositar feromonas\n",
        "            for route in routes:\n",
        "                if not route or len(route) == 0:\n",
        "                    continue\n",
        "\n",
        "                route_distance = self.sum_length(route)\n",
        "                if route_distance > 0:\n",
        "                    pheromone_deposit = 1.0 / route_distance\n",
        "\n",
        "                    # Depot -> primer nodo\n",
        "                    if route[0] < len(tau):\n",
        "                        tau[0, route[0]] += pheromone_deposit\n",
        "                        tau[route[0], 0] += pheromone_deposit\n",
        "\n",
        "                    # Nodos consecutivos en la ruta\n",
        "                    for i in range(len(route) - 1):\n",
        "                        if route[i] < len(tau) and route[i+1] < len(tau):\n",
        "                            tau[route[i], route[i+1]] += pheromone_deposit\n",
        "                            tau[route[i+1], route[i]] += pheromone_deposit\n",
        "\n",
        "                    # Último nodo -> depot\n",
        "                    if route[-1] < len(tau):\n",
        "                        tau[route[-1], 0] += pheromone_deposit\n",
        "                        tau[0, route[-1]] += pheromone_deposit\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error en _update_pheromones: {str(e)}\")\n",
        "\n",
        "    def _local_search_2opt(self, route):\n",
        "        \"\"\"Optimización local 2-opt simple\"\"\"\n",
        "        if not route or len(route) <= 2:\n",
        "            return route\n",
        "\n",
        "        try:\n",
        "            best_route = route.copy()\n",
        "            best_distance = self.sum_length(best_route)\n",
        "            improved = True\n",
        "\n",
        "            while improved:\n",
        "                improved = False\n",
        "                for i in range(1, len(route) - 1):\n",
        "                    for j in range(i + 1, len(route)):\n",
        "                        # Crear nueva ruta con 2-opt swap\n",
        "                        new_route = route[:i] + route[i:j+1][::-1] + route[j+1:]\n",
        "                        new_distance = self.sum_length(new_route)\n",
        "\n",
        "                        if new_distance < best_distance:\n",
        "                            best_route = new_route\n",
        "                            best_distance = new_distance\n",
        "                            improved = True\n",
        "                            break\n",
        "                    if improved:\n",
        "                        break\n",
        "                route = best_route\n",
        "\n",
        "            return best_route\n",
        "        except:\n",
        "            return route\n",
        "\n",
        "\n",
        "def process_single_instance(args):\n",
        "    \"\"\"Procesa una instancia individual del dataset\"\"\"\n",
        "    idx, row = args\n",
        "\n",
        "    try:\n",
        "        print(f\"Procesando instancia {idx}\")\n",
        "\n",
        "        # Cargar datos\n",
        "        nodes = pd.read_parquet(row['nodes'])\n",
        "        distance_matrix = pd.read_parquet(row['distance_matrix'])\n",
        "        vehicle_capacity = row['vehicle_capacity']\n",
        "        problem_cluster = row['problem_cluster']\n",
        "\n",
        "        print(f\"Instancia {idx}: {len(nodes)} nodos, capacidad {vehicle_capacity}\")\n",
        "\n",
        "        # Configurar solver\n",
        "        aco_solver = ACOSolver(\n",
        "            alpha=1.0,\n",
        "            beta=2.0,\n",
        "            rho=0.1,\n",
        "            max_iters=30,  # Reducido para debugging\n",
        "            ants=min(15, len(nodes))\n",
        "        )\n",
        "\n",
        "        # Resolver\n",
        "        best_routes = aco_solver.solve(nodes, distance_matrix, vehicle_capacity)\n",
        "\n",
        "        if best_routes and len(best_routes) > 0:\n",
        "            best_value = aco_solver.solution_length(best_routes)\n",
        "            n_vehicles = len(best_routes)\n",
        "            print(f\"Instancia {idx} resuelta: {n_vehicles} vehículos, distancia {best_value:.2f}\")\n",
        "        else:\n",
        "            print(f\"Instancia {idx} falló: no se encontraron rutas\")\n",
        "            best_value = None\n",
        "            n_vehicles = 0\n",
        "\n",
        "        return {\n",
        "            'problem_cluster': problem_cluster,\n",
        "            'vehicle_capacity': vehicle_capacity,\n",
        "            'aco_best_route': best_routes,\n",
        "            'aco_best_value': best_value,\n",
        "            'aco_n_vehicles': n_vehicles,\n",
        "            'status': 'success' if best_routes else 'no_solution'\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando instancia {idx}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        return {\n",
        "            'problem_cluster': row.get('problem_cluster', 'unknown'),\n",
        "            'vehicle_capacity': row.get('vehicle_capacity', 0),\n",
        "            'aco_best_route': [],\n",
        "            'aco_best_value': None,\n",
        "            'aco_n_vehicles': 0,\n",
        "            'status': f'error: {str(e)}'\n",
        "        }\n",
        "\n",
        "\n",
        "def process_dataset(df, n_workers=None):\n",
        "    \"\"\"Función principal para procesar el dataset\"\"\"\n",
        "    if n_workers is None:\n",
        "        n_workers = min(mp.cpu_count(), 4)  # Limitar workers para debugging\n",
        "\n",
        "    print(f\"Procesando {len(df)} instancias con {n_workers} workers\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    if n_workers == 1:\n",
        "        # Procesamiento secuencial para debugging\n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "            result = process_single_instance((idx, row))\n",
        "            results.append(result)\n",
        "    else:\n",
        "        # Procesamiento paralelo\n",
        "        with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
        "            # Enviar trabajos\n",
        "            future_to_idx = {\n",
        "                executor.submit(process_single_instance, (idx, row)): idx\n",
        "                for idx, row in df.iterrows()\n",
        "            }\n",
        "\n",
        "            # Recopilar resultados\n",
        "            for future in tqdm(as_completed(future_to_idx),\n",
        "                              total=len(future_to_idx),\n",
        "                              desc=\"Procesando\"):\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "                except Exception as e:\n",
        "                    idx = future_to_idx[future]\n",
        "                    print(f\"Error en worker para índice {idx}: {e}\")\n",
        "                    results.append({\n",
        "                        'problem_cluster': 'error',\n",
        "                        'vehicle_capacity': 0,\n",
        "                        'aco_best_route': [],\n",
        "                        'aco_best_value': None,\n",
        "                        'aco_n_vehicles': 0,\n",
        "                        'status': f'worker_error: {str(e)}'\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# Función de prueba simple\n",
        "def test_single_instance():\n",
        "    \"\"\"Prueba con una instancia simple para verificar funcionamiento\"\"\"\n",
        "    # Crear datos de prueba simples\n",
        "    n_nodes = 6\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Crear nodos con demandas\n",
        "    nodes = pd.DataFrame({\n",
        "        'demand': [0, 10, 15, 20, 12, 8]  # depot tiene demanda 0\n",
        "    })\n",
        "\n",
        "    # Crear matriz de distancias simétrica\n",
        "    coords = np.random.rand(n_nodes, 2) * 100\n",
        "    dist_matrix = np.zeros((n_nodes, n_nodes))\n",
        "    for i in range(n_nodes):\n",
        "        for j in range(n_nodes):\n",
        "            dist_matrix[i, j] = np.sqrt(np.sum((coords[i] - coords[j])**2))\n",
        "\n",
        "    distance_matrix = pd.DataFrame(dist_matrix)\n",
        "    capacity = 30\n",
        "\n",
        "    print(\"Probando instancia simple...\")\n",
        "    solver = ACOSolver(max_iters=20, ants=10)\n",
        "    routes = solver.solve(nodes, distance_matrix, capacity)\n",
        "\n",
        "    print(f\"Rutas encontradas: {routes}\")\n",
        "    if routes:\n",
        "        print(f\"Distancia total: {solver.solution_length(routes):.2f}\")\n",
        "        print(f\"Número de vehículos: {len(routes)}\")\n",
        "\n",
        "    return routes"
      ],
      "metadata": {
        "id": "myusFq697tuz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clusterizacion + ACO"
      ],
      "metadata": {
        "id": "obnYWW5Nq3oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_cluster_mejorado(coords, demandas, capacidad, matriz):\n",
        "    \"\"\"\n",
        "    Clusterización greedy: respeta capacidad y selecciona clientes por demanda/distancia.\n",
        "    \"\"\"\n",
        "    restantes = set(range(1, len(demandas)))\n",
        "    clusters = []\n",
        "\n",
        "    while restantes:\n",
        "        cluster = [0]  # siempre empieza en el depósito\n",
        "        carga, actual = 0, 0\n",
        "\n",
        "        while True:\n",
        "            candidatos = [j for j in restantes if demandas[j] + carga <= capacidad]\n",
        "            if not candidatos:\n",
        "                break\n",
        "\n",
        "            siguiente = max(\n",
        "                candidatos,\n",
        "                key=lambda j: demandas[j] / (matriz[actual, j] + 1e-6)\n",
        "            )\n",
        "\n",
        "            cluster.append(siguiente)\n",
        "            carga += demandas[siguiente]\n",
        "            restantes.remove(siguiente)\n",
        "            actual = siguiente\n",
        "\n",
        "        clusters.append(cluster)\n",
        "    return clusters\n"
      ],
      "metadata": {
        "id": "BzgSaBFfrIVj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ugtJkSFre0rI"
      },
      "outputs": [],
      "source": [
        "def aplicar_aco_solver_clusters(clusters, nodes, distance_matrix, capacity, ants, n_iter, alpha, beta, rho):\n",
        "    resultados = []\n",
        "    distancia_total = 0\n",
        "\n",
        "    for cluster in clusters:\n",
        "        # Extraemos subgrafo del cluster\n",
        "        sub_nodes = nodes.iloc[cluster].reset_index(drop=True)\n",
        "        sub_dm = distance_matrix.iloc[cluster, cluster].reset_index(drop=True).T.reset_index(drop=True)\n",
        "\n",
        "        solver = ACOSolver(alpha=alpha, beta=beta, rho=rho, ants=ants, max_iters=n_iter)\n",
        "        rutas = solver.solve(sub_nodes, sub_dm, capacity)\n",
        "\n",
        "        if rutas:\n",
        "            rutas_globales = [[cluster[i] for i in ruta] for ruta in rutas]\n",
        "            resultados.extend(rutas_globales)\n",
        "            distancia_total += solver.solution_length(rutas)\n",
        "\n",
        "    return resultados, len(resultados), distancia_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "imdK3w76ndLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c6864f-e986-4a4f-9c17-c40abff98744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WW7AnTSgSVX7Ktn2z6GyHkQN3nbmqaRa\n",
            "To: /content/archive.zip\n",
            "100%|██████████| 847k/847k [00:00<00:00, 8.34MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "if not os.path.exists(\"carpeta_descomprimida\"):\n",
        "\n",
        "  file_path = \"https://drive.google.com/uc?id=1WW7AnTSgSVX7Ktn2z6GyHkQN3nbmqaRa\"\n",
        "  output = \"archive.zip\"\n",
        "  gdown.download(file_path, output, quiet=False)\n",
        "\n",
        "\n",
        "  with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "      zip_ref.extractall('carpeta_descomprimida')\n",
        "\n",
        "  os.remove(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VNKIL4WOxZ3R"
      },
      "outputs": [],
      "source": [
        "def obtener_datos_grafo(grafo):\n",
        "    nodos = grafo.get_node_table()\n",
        "\n",
        "    matriz_distancia = grafo.get_distance_matrix().values\n",
        "    coords = nodos[['x', 'y']].values\n",
        "    demandas = nodos['demand'].values\n",
        "\n",
        "    return coords, matriz_distancia, demandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_consulta = pd.read_excel(\"carpeta_descomprimida/problemset/problemset.xlsx\")\n"
      ],
      "metadata": {
        "id": "Q2tI7O1t2lB0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0s05AbNxt5Vy"
      },
      "outputs": [],
      "source": [
        "def extraer_capacidades(problema):\n",
        "  capacidades_disponibles = benchmark_consulta[benchmark_consulta['problem_cluster'] == problema]['vehicle_capacity'].to_list()\n",
        "  return capacidades_disponibles\n",
        "\n",
        "def resultados(problema):\n",
        "  folder = \"carpeta_descomprimida/problemset/in\"\n",
        "\n",
        "  g = Graph(problema, folder)\n",
        "\n",
        "  nodos, matriz_distancia = obtener_datos_grafo(g)\n",
        "  capacidades = extraer_capacidades(problema)\n",
        "\n",
        "  coords = nodos[['x', 'y']].values\n",
        "  demandas = nodos['demand'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class Graph:\n",
        "    def __init__(self, problem_name, folder):\n",
        "        self.problem_name = problem_name\n",
        "        self.folder = folder\n",
        "\n",
        "        nodes_file = os.path.join(folder, f\"{problem_name}_nodes.parquet\")\n",
        "        matrix_file = os.path.join(folder, f\"{problem_name}_dm.parquet\")\n",
        "\n",
        "\n",
        "        self.nodes_df = pd.read_parquet(nodes_file)\n",
        "        self.matriz_df = pd.read_parquet(matrix_file)\n",
        "\n",
        "    def get_node_table(self):\n",
        "        return self.nodes_df\n",
        "\n",
        "    def get_distance_matrix(self):\n",
        "        return self.matriz_df\n"
      ],
      "metadata": {
        "id": "hB9QAPBp16xO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tracemalloc\n",
        "\n",
        "def evaluar_algoritmo_aco(evap_rate, alpha, beta, ants, lista_de_problemas, benchmark_consulta):\n",
        "    resultados = []\n",
        "    contador = 0\n",
        "\n",
        "    error_general_distancia = 0\n",
        "    error_cuadrado_distancia = 0\n",
        "\n",
        "    folder = \"carpeta_descomprimida/problemset/in\"\n",
        "\n",
        "    for problema in lista_de_problemas:\n",
        "        g = Graph(problema, folder)\n",
        "\n",
        "        coords, matriz_distancia, demandas = obtener_datos_grafo(g)\n",
        "        capacidades = extraer_capacidades(problema)\n",
        "\n",
        "        nodes_df = g.get_node_table()\n",
        "        dist_df = g.get_distance_matrix()\n",
        "\n",
        "        for capacidad in capacidades:\n",
        "            # Iniciar medición de tiempo y memoria\n",
        "            tracemalloc.start()\n",
        "            tiempo_inicio = time.time()\n",
        "\n",
        "            clusters = greedy_cluster_mejorado(coords, demandas, capacidad, matriz_distancia)\n",
        "\n",
        "            # Paso 2: Aplicar ACOSolver en cada cluster\n",
        "            rutas_totales = []\n",
        "            distancia_total = 0\n",
        "\n",
        "            for cluster in clusters:\n",
        "                sub_nodes = nodes_df.iloc[cluster].reset_index(drop=True)\n",
        "                sub_dm = dist_df.iloc[cluster, cluster].reset_index(drop=True).T.reset_index(drop=True)\n",
        "\n",
        "                solver = ACOSolver(alpha=alpha, beta=beta, rho=evap_rate, ants=ants, max_iters=15)\n",
        "                rutas = solver.solve(sub_nodes, sub_dm, capacidad)\n",
        "\n",
        "                if rutas:\n",
        "                    # Mapeamos índices locales -> globales\n",
        "                    rutas_globales = [[cluster[i] for i in ruta] for ruta in rutas]\n",
        "                    rutas_totales.extend(rutas_globales)\n",
        "                    distancia_total += solver.solution_length(rutas)\n",
        "\n",
        "            # Finalizar medición de tiempo y memoria\n",
        "            tiempo_fin = time.time()\n",
        "            tiempo_ejecucion = tiempo_fin - tiempo_inicio\n",
        "            memoria_actual, memoria_pico = tracemalloc.get_traced_memory()\n",
        "            tracemalloc.stop()\n",
        "\n",
        "            cantidad_vehiculos = len(rutas_totales)\n",
        "\n",
        "            # Paso 3: Comparar con benchmark\n",
        "            prueba = benchmark_consulta[\n",
        "                (benchmark_consulta['problem_cluster'] == problema) &\n",
        "                (benchmark_consulta['vehicle_capacity'] == capacidad)\n",
        "            ][['aco best value', 'aco n vehicles']]\n",
        "\n",
        "            if prueba.empty:\n",
        "                print(f\" Problema {problema} con capacidad {capacidad} no está en benchmark\")\n",
        "                continue\n",
        "\n",
        "            index = int(prueba.index[0])\n",
        "            aco_best_value = prueba.loc[index, 'aco best value']\n",
        "            aco_n_vehicles = prueba.loc[index, 'aco n vehicles']\n",
        "\n",
        "            # Errores\n",
        "\n",
        "            error_distancia = abs(distancia_total - aco_best_value)\n",
        "            contador += 1\n",
        "            error_general_distancia += error_distancia\n",
        "            error_cuadrado_distancia += error_distancia ** 2\n",
        "\n",
        "            # Promedios\n",
        "            error_promedio_distancia = error_general_distancia / contador if contador > 0 else float('inf')\n",
        "            error_cuadrad_promedio_distancia = error_cuadrado_distancia / contador if contador > 0 else float('inf')\n",
        "\n",
        "            resultados.append({\n",
        "                \"problema\": problema,\n",
        "                \"capacidad\": capacidad,\n",
        "                \"vehiculos\": cantidad_vehiculos,\n",
        "                \"distancia\": distancia_total,\n",
        "                \"tiempo_segundos\": tiempo_ejecucion,\n",
        "                \"memoria_mb\": memoria_pico / (1024 * 1024),\n",
        "                \"problemset_aco_best_value\": aco_best_value,\n",
        "                \"problemset_aco_n_vehicles\": aco_n_vehicles,\n",
        "                \"error_abs_distancia\": error_distancia,\n",
        "                \"error_rel_distancia\": error_distancia / aco_best_value if aco_best_value != 0 else float('inf'),\n",
        "                \"error_promedio_distancia\": error_promedio_distancia,\n",
        "                \"error_cuadrad_promedio_distancia\": error_cuadrad_promedio_distancia\n",
        "            })\n",
        "\n",
        "    return resultados, error_promedio_distancia, error_cuadrad_promedio_distancia"
      ],
      "metadata": {
        "id": "OGJjpjE1UG0p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = \"carpeta_descomprimida/problemset/in\"\n",
        "for f in os.listdir(folder):\n",
        "    print(f)\n"
      ],
      "metadata": {
        "id": "YKSYZMKo3AmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f346ce-8009-417d-9854-131d01503c37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medium-50n-c80_120-d10_50_nodes.parquet\n",
            "big-250n-c80_120-d10_50_dm.parquet\n",
            "small-10n-c30_75-d15_nodes.parquet\n",
            "small-10n-c30_75-d15_dm.parquet\n",
            "big-250n-c80_120-d10_50_nodes.parquet\n",
            "medium-50n-c150_200-d10_50_nodes.parquet\n",
            "medium-50n-c150_200-d10_50_dm.parquet\n",
            "big-250n-c150_300-d10_50_nodes.parquet\n",
            "small-10n-c50-d10_50_dm.parquet\n",
            "medium-50n-c150_200-d15_dm.parquet\n",
            "small-10n-c80_120-d10_50_nodes.parquet\n",
            "small-10n-c50_70-d10_50_nodes.parquet\n",
            "big-250n-c150_300-d15_nodes.parquet\n",
            "small-10n-c50_70-d10_50_dm.parquet\n",
            "big-250n-c150_300-d10_50_dm.parquet\n",
            "medium-50n-c80_120-d10_50_dm.parquet\n",
            "small-10n-c80_120-d10_50_dm.parquet\n",
            "small-10n-c50_60-d10_50_nodes.parquet\n",
            "small-10n-c50-d10_50_nodes.parquet\n",
            "medium-50n-c150_200-d15_nodes.parquet\n",
            "small-10n-c50_60-d10_50_dm.parquet\n",
            "big-250n-c150_300-d15_dm.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lZAYTUgH3d6H"
      },
      "outputs": [],
      "source": [
        "# Crear lista de problemas desde el benchmark\n",
        "lista_de_problemas = benchmark_consulta['problem_cluster'].unique().tolist()\n",
        "\n",
        "# Ejecutar la evaluación\n",
        "resultados, error_promedio_distancia, \\\n",
        "error_cuadrad_promedio_distancia = evaluar_algoritmo_aco(\n",
        "    0.5,     # evap_rate\n",
        "    1,       # alpha\n",
        "    5,       # beta\n",
        "    20,      # ants\n",
        "    lista_de_problemas,\n",
        "    benchmark_consulta\n",
        ")\n",
        "\n",
        "# Mostrar resultados\n",
        "text = f\"\"\"\n",
        "Estadísticas o métricas del algoritmo creado en comparación con el problemset:\n",
        "\n",
        "Error promedio de la distancia: {error_promedio_distancia}\n",
        "Error cuadrado promedio de la distancia: {error_cuadrad_promedio_distancia}\n",
        "\"\"\"\n",
        "\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(resultados)\n",
        "results"
      ],
      "metadata": {
        "id": "aZZMnKVs4WzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resultados a excell\n",
        "results.to_excel(\"resultadosVRP.xlsx\")"
      ],
      "metadata": {
        "id": "ltxaC0n5Fekg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}